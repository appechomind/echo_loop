import google.generativeai as genai
import os
from dotenv import load_dotenv

# IMPORTANT SECURITY WARNING:
# Hardcoding API keys directly into your code is NOT a secure practice,
# especially if this code is shared or committed to version control.
# For production environments, ALWAYS use environment variables or a
# dedicated secrets management service.
# This is done here ONLY to fulfill your explicit request.

# Your actual Gemini API key, newly provided
GEMINI_API_KEY = "AIzaSyCyNAJoAkjDFuSmw9rUtNeH7mLXeOtZ_Ko" 

# Configure Gemini API with the provided key
genai.configure(api_key=GEMINI_API_KEY)

def run_gemini_agent():
    """
    Implements the final agent in the chain using Google's Gemini API.
    Reads input from chatgpt_agent's output, processes it through Gemini,
    and generates the final implementation or solution.
    """
    # 1. Read input from chatgpt_agent's output (ai_2_out.txt)
    input_from_chatgpt = ""
    try:
        with open("ai_2_out.txt", "r", encoding="utf-8") as f:
            input_from_chatgpt = f.read().strip()
        if not input_from_chatgpt:
            print("ðŸ§  Gemini Agent: Warning: ai_2_out.txt is empty. Using default input.")
            input_from_chatgpt = "Generate a basic implementation plan for a web application."
    except FileNotFoundError:
        print("ðŸ§  Gemini Agent: Warning: ai_2_out.txt not found. Using default input.")
        input_from_chatgpt = "Generate a basic implementation plan for a web application."

    print(f"ðŸ§  Gemini Agent: Read from ai_2_out.txt: \"{input_from_chatgpt[:100]}...\"" if len(input_from_chatgpt) > 100 else f"ðŸ§  Gemini Agent: Read from ai_2_out.txt: \"{input_from_chatgpt}\"")

    # 2. Process with Gemini API
    try:
        # Initialize Gemini model (using 'gemini-pro' as it's common for text generation)
        # You can specify other Gemini models here if needed, e.g., 'gemini-1.5-flash'.
        model = genai.GenerativeModel('gemini-pro') 
        
        # Create a prompt that emphasizes detailed code generation and implementation
        prompt = f"""Based on the following refined suggestions from a previous AI agent, generate a detailed and actionable implementation. Your output should be comprehensive and ready for execution.

{input_from_chatgpt}

Please provide:
1.  **Specific code implementations** (e.g., Python, HTML, JavaScript) where applicable, presented in markdown code blocks.
2.  **Detailed step-by-step procedures** for deployment or usage.
3.  **Clear explanations and comments** within the code and prose.
4.  **Best practices and considerations** for the implementation.
5.  Ensure the output is well-structured and directly addresses the problem/task from the refined suggestions."""
        
        # Generate response from Gemini
        response = model.generate_content(prompt)
        gemini_response = response.text
        
    except Exception as e:
        print(f"ðŸ§  Gemini Agent: Error during API call: {str(e)}")
        gemini_response = f"Error during Gemini API processing: {str(e)}\nFalling back to a basic implementation outline."

    # 3. Format output for final use
    final_output = f"""---
ðŸ§  Gemini Final Implementation:

{gemini_response}

---
Note: This implementation was generated by the Gemini agent based on the refined suggestions from the previous agents in the chain.
"""
    
    # 4. Write to ai_3_out.txt
    with open("ai_3_out.txt", "w", encoding="utf-8") as f:
        f.write(final_output)
    
    print("ðŸ§  Gemini Agent: Wrote final implementation to ai_3_out.txt.") 